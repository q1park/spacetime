{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacetime.spacetime import SpaceTime\n",
    "from spacetime.simulate import Simulator\n",
    "from spacetime.metrics import count_accuracy, adjacency_error\n",
    "from spacetime.models import MLPEncoder, MLPDecoder\n",
    "from spacetime.training import train, acyclicity\n",
    "from spacetime.utils import arguments, spacetime_mutilator, graph_clipper\n",
    "from spacetime.sampler import NodeData, GraphSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulating a random 3-degree erdos-renyi dag with range (0.5, 2.0) (seed 0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        , -0.89683342,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , -0.5281847 , -1.41814358],\n",
       "       [ 0.        ,  0.        ,  0.        , -1.50015007,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  1.15554793],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "args = arguments(node_dict = {0:[0,1], 1:[2], 2:[3], 3:[4]})\n",
    "args.data_sample_size=10000\n",
    "args.noise_scale = 0.6\n",
    "args.graph_type='erdos-renyi'\n",
    "args.graph_sem_type='linear-gauss'\n",
    "args.graph_linear_type='linear'\n",
    "args.graph_degree = 3\n",
    "\n",
    "# training hyperparameters\n",
    "args.graph_threshold=0.3  # 0.3 is good 0.2 is error prune\n",
    "args.tau_A=1e-8\n",
    "args.ordered_graph=True\n",
    "args.use_A_connect_loss=False\n",
    "args.use_A_positiver_loss=False\n",
    "\n",
    "args.seed=42\n",
    "args.epochs=5\n",
    "args.batch_size=100 # note: should be divisible by sample size otherwise throw an error\n",
    "args.encoder_hidden=64\n",
    "args.decoder_hidden=64\n",
    "\n",
    "g = SpaceTime.from_spacelike([0,1,3,2,4], simulate=True,\n",
    "                             degree=args.graph_degree, graph_type=args.graph_type, \n",
    "                             w_range=(0.5,2.0), force_positive=False, seed=0)\n",
    "g.show_adj()\n",
    "g.draw_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_plot_dict = {0:(4,3), 1:(4,1), 2:(3,2), 3:(2,0)}\n",
    "mutilate = 3\n",
    "observe = 4\n",
    "latent = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulating 10000 samples from a linear-gauss sem with linear causal effects\n"
     ]
    }
   ],
   "source": [
    "g.data = Simulator.sem(graph=g.graph, n=args.data_sample_size, x_dims=args.x_dims, \n",
    "                       sem_type=args.graph_sem_type, linear_type=args.graph_linear_type, \n",
    "                       noise_scale=args.noise_scale, seed=args.seed)\n",
    "train_loader, test_loader = g.torch_loader(g.data, args.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_trials = 1\n",
    "\n",
    "# shd_trials = list()\n",
    "# err_trials = list()\n",
    "# kl_trials = list()\n",
    "# nll_trials = list()\n",
    "# elbo_trials = list()\n",
    "# graph_trials = list()\n",
    "\n",
    "# for trial in range(n_trials):\n",
    "#     shd_train, err_train = list(), list()\n",
    "#     kl_train, nll_train, elbo_train = list(), list(), list()\n",
    "#     hA_train = list()\n",
    "#     graph_train = list()\n",
    "\n",
    "#     best_epoch = 0\n",
    "#     best_ELBO, best_ELBO_graph = np.inf, None\n",
    "#     best_KL, best_KL_graph = np.inf, None\n",
    "#     best_NLL, best_NLL_graph = np.inf, None\n",
    "\n",
    "#     # optimizer step on hyparameters\n",
    "#     c_A = args.c_A\n",
    "#     lambda_A = args.lambda_A\n",
    "    \n",
    "#     h_A_old, h_A_new = np.inf, torch.tensor(1.)\n",
    "#     h_tol = args.h_tol\n",
    "#     k_max_iter = int(args.k_max_iter)\n",
    "\n",
    "#     #===================================\n",
    "#     # load modules\n",
    "#     #===================================\n",
    "#     # add adjacency matrix A\n",
    "#     num_nodes = args.data_variable_size\n",
    "#     adj_A = np.zeros((num_nodes, num_nodes))\n",
    "\n",
    "#     encoder = MLPEncoder(args.x_dims, args.encoder_hidden, int(args.z_dims), adj_A).double()\n",
    "#     decoder = MLPDecoder(args.z_dims, args.x_dims, n_hid=args.decoder_hidden).double()\n",
    "\n",
    "#     #===================================\n",
    "#     # set up training parameters\n",
    "#     #===================================\n",
    "#     optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()),lr=args.lr)\n",
    "#     scheduler = lr_scheduler.StepLR(optimizer, step_size=args.lr_decay, gamma=args.gamma)\n",
    "\n",
    "#     #===================================\n",
    "#     # train model\n",
    "#     #===================================\n",
    "#     t_total = time.time()\n",
    "#     for step_k in range(k_max_iter):\n",
    "#         while c_A < 1e+20:\n",
    "#             for epoch in range(args.epochs):\n",
    "#                 ELBO, KL, NLL, origin_A = train(lambda_A, c_A, optimizer, scheduler, \n",
    "#                                                 encoder, decoder, train_loader, args)\n",
    "#                 graph_clone, graph_full, graph = graph_clipper(origin_A, args.graph_threshold)\n",
    "                \n",
    "#                 if ELBO < best_ELBO:\n",
    "#                     best_epoch = epoch\n",
    "#                     best_ELBO = ELBO\n",
    "#                     best_ELBO_graph = graph\n",
    "#                     best_ELBO_graph_full = graph_full\n",
    "\n",
    "#                 if KL < best_KL:\n",
    "#                     best_KL = KL\n",
    "#                     best_KL_graph = graph\n",
    "\n",
    "#                 if NLL < best_NLL:\n",
    "#                     best_NLL = NLL\n",
    "#                     best_NLL_graph = graph\n",
    "                \n",
    "#                 hA = acyclicity(graph_clone, args)\n",
    "#                 fdr, tpr, fpr, shd, nnz = count_accuracy(g.show_adj(), best_ELBO_graph)\n",
    "#                 err = adjacency_error(g.show_adj(), best_ELBO_graph_full)\n",
    "\n",
    "#                 shd_train.append(shd)\n",
    "#                 err_train.append(err)\n",
    "#                 kl_train.append(best_KL)\n",
    "#                 nll_train.append(best_NLL)\n",
    "#                 elbo_train.append(best_ELBO)\n",
    "#                 hA_train.append(hA)\n",
    "                \n",
    "#             graph_train.append(best_ELBO_graph_full)\n",
    "#             print(\"Optimization Finished!\")\n",
    "#             print(\"Best Epoch: {:04d}\\t\".format(best_epoch),\n",
    "#                   \"ELBO: {:.10f}\".format(best_ELBO),\n",
    "#                   \"KL: {:.10f}\".format(best_KL),\n",
    "#                   \"NLL: {:.10f}\".format(best_NLL))\n",
    "            \n",
    "#             if ELBO > 2 * best_ELBO:\n",
    "#                 break\n",
    "\n",
    "#             # update parameters\n",
    "#             h_A_new = acyclicity(graph_clone, args)\n",
    "#             if h_A_new.item() > 0.25 * h_A_old:\n",
    "#                 c_A*=10\n",
    "#             else:\n",
    "#                 break\n",
    "\n",
    "#         h_A_old = h_A_new.item()\n",
    "#         lambda_A += c_A * h_A_new.item()\n",
    "\n",
    "#         if h_A_new.item() <= h_tol:\n",
    "#             break\n",
    "\n",
    "#     print(\"\\nTrial %s finished in %s seconds\"%(trial, time.time() - t_total))\n",
    "#     print('Best ELBO Stats: shd %s err %s\\n'%(shd, err))\n",
    "# #     print(best_ELBO_graph)\n",
    "\n",
    "# #     print('Ground truth graph')\n",
    "# #     print(g.show_adj(around=3))\n",
    "    \n",
    "#     shd_trials.append(shd_train)\n",
    "#     err_trials.append(err_train)\n",
    "#     kl_trials.append(kl_train)\n",
    "#     nll_trials.append(nll_train)\n",
    "#     elbo_trials.append(elbo_train)\n",
    "#     graph_trials.append(best_ELBO_graph)\n",
    "# pass;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(1, 5, figsize = (15,3))\n",
    "\n",
    "# for trial in range(n_trials):\n",
    "#     axs[0].plot(range(len(err_trials[trial])), err_trials[trial])\n",
    "#     axs[1].plot(range(len(shd_trials[trial])), shd_trials[trial])\n",
    "#     axs[2].plot(range(len(kl_trials[trial])), np.log10(kl_trials[trial]))\n",
    "#     axs[3].plot(range(len(nll_trials[trial])), np.log10(nll_trials[trial]))\n",
    "#     axs[4].plot(range(len(elbo_trials[trial])), np.log10(elbo_trials[trial]))\n",
    "# pass;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attn Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy, math\n",
    "import seaborn as sns\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "def draw(data, x, y, ax):\n",
    "    sns.heatmap(data, xticklabels=x, square=True, yticklabels=y, \n",
    "                vmin=0.0, vmax=1.0, cbar=False, ax=ax)\n",
    "    \n",
    "def node_hot(x, pad=(0,0)):\n",
    "    expanded = torch.eye(x.shape[1])*x.unsqueeze(1)\n",
    "    return F.pad(expanded, pad=(*pad, 0, 0), mode='constant', value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \"Construct a layernorm module (See citation for details).\"\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2\n",
    "\n",
    "class SublayerConnection(nn.Module):\n",
    "    \"\"\"\n",
    "    A residual connection followed by a layer norm.\n",
    "    Note for code simplicity the norm is first as opposed to last.\n",
    "    \"\"\"\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x, sublayer):\n",
    "        \"Apply residual connection to any sublayer with the same size.\"\n",
    "        return x + self.dropout(sublayer(self.norm(x)))\n",
    "    \n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "    def __init__(self, d_embed, dropout, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_embed)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_embed, 2) *\n",
    "                             -(math.log(10000.0) / d_embed))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + Variable(self.pe[:, :x.size(1)], \n",
    "                         requires_grad=False)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearBlock(nn.Module):\n",
    "    \"Implements FFN equation.\"\n",
    "    def __init__(self, d_in, d_hidden, d_out, dropout=0.1):\n",
    "        super(LinearBlock, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_in, d_hidden)\n",
    "        self.w_2 = nn.Linear(d_hidden, d_out)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight.data)\n",
    "                m.bias.data.fill_(0.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(F.relu(self.w_1(x))))\n",
    "    \n",
    "class EmbedBlock(nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super(EmbedBlock, self).__init__()\n",
    "        self.proj = nn.Linear(d_in, d_out)\n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight.data)\n",
    "                m.bias.data.fill_(0.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.proj(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    \"Encoder is made up of self-attn and feed forward (defined below)\"\n",
    "    def __init__(self, d_embed, self_attn, feed_forward, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(d_embed, dropout), 2)\n",
    "        self.d_embed = d_embed\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"Follow Figure 1 (left) for connections.\"\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x))\n",
    "        return self.sublayer[1](x, self.feed_forward)\n",
    "\n",
    "# class DecoderLayer(nn.Module):\n",
    "#     \"Decoder is made of self-attn, src-attn, and feed forward (defined below)\"\n",
    "#     def __init__(self, d_embed, self_attn, src_attn, feed_forward, dropout):\n",
    "#         super(DecoderLayer, self).__init__()\n",
    "#         self.d_embed = d_embed\n",
    "#         self.self_attn = self_attn\n",
    "#         self.src_attn = src_attn\n",
    "#         self.feed_forward = feed_forward\n",
    "#         self.sublayer = SublayerConnection(d_embed, dropout)\n",
    "#         self.norm = LayerNorm(d_embed)\n",
    " \n",
    "#     def forward(self, x, memory):\n",
    "#         \"Follow Figure 1 (right) for connections.\"\n",
    "#         m = memory\n",
    "#         x = self.norm(self.self_attn(x, x, x))\n",
    "#         x = self.norm(self.src_attn(x, m, m))\n",
    "#         return self.sublayer(x, self.feed_forward)\n",
    "    \n",
    "class DecoderLayer(nn.Module):\n",
    "    \"Decoder is made of self-attn, src-attn, and feed forward (defined below)\"\n",
    "    def __init__(self, d_embed, self_attn, src_attn, feed_forward, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.d_embed = d_embed\n",
    "        self.self_attn = self_attn\n",
    "        self.src_attn = src_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(d_embed, dropout), 3)\n",
    " \n",
    "    def forward(self, x, memory):\n",
    "        \"Follow Figure 1 (right) for connections.\"\n",
    "        m = memory\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x))\n",
    "        x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m))\n",
    "        return self.sublayer[2](x, self.feed_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
    "\n",
    "def clone_encoder(mask, N, **kwargs):\n",
    "    d_embed, d_hidden = kwargs['d_embed'], kwargs['d_hidden']\n",
    "    self_attns = [CausalAttention(n_heads, d_embed, mask=mask) for _ in range(N)]\n",
    "    feed_forwards = [LinearBlock(d_embed, d_hidden, d_embed, dropout=0.1) for _ in range(N)]\n",
    "    modules = [EncoderLayer(d_embed, self_attn, feed_forward, dropout) \n",
    "               for self_attn, feed_forward in zip(self_attns, feed_forwards)]\n",
    "\n",
    "    return nn.ModuleList(modules)\n",
    "\n",
    "def clone_decoder(mask, N, **kwargs):\n",
    "    d_embed, d_hidden = kwargs['d_embed'], kwargs['d_hidden']\n",
    "    self_attns = [CausalAttention(n_heads, d_embed, mask=mask, mask_self=True) for _ in range(N)]\n",
    "    src_attns = [CausalAttention(n_heads, d_embed, mask=mask, mask_self=True) for _ in range(N)]\n",
    "    feed_forwards = [LinearBlock(d_embed, d_hidden, d_embed, dropout=0.1) for _ in range(N)]\n",
    "    \n",
    "    modules = [DecoderLayer(d_embed, self_attn, src_attn, feed_forward, dropout) \n",
    "               for self_attn, src_attn, feed_forward in zip(self_attns, src_attns, feed_forwards)]\n",
    "    return nn.ModuleList(modules)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"Core encoder is a stack of N layers\"\n",
    "    def __init__(self, mask, n_nodes, d_embed, d_hidden, n_layers, n_heads, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.mask = mask\n",
    "        self.layers = clone_encoder(self.mask, n_layers, d_embed=d_embed, d_hidden=d_hidden, dropout=dropout)\n",
    "        self.norm = LayerNorm(self.layers[0].d_embed)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"Pass the input through each layer in turn.\"\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return self.norm(x)\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    \"Generic N layer decoder with masking.\"\n",
    "    def __init__(self, mask, n_nodes, d_embed, d_hidden, n_layers, n_heads, dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.mask = mask\n",
    "        self.layers = clone_decoder(self.mask, n_layers, d_embed=d_embed, d_hidden=d_hidden, dropout=dropout)\n",
    "        self.norm = LayerNorm(self.layers[0].d_embed)\n",
    "        \n",
    "    def forward(self, x, memory):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, memory)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testt = torch.Tensor(g.show_adj())\n",
    "testt[testt!=0]=1.0\n",
    "testt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A standard Encoder-Decoder architecture. Base for this and many other models.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes, d_embed, d_hidden, n_layers, n_heads, dropout):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.e_mask = torch.eye(n_nodes).unsqueeze(0)\n",
    "#         self.e_mask = torch.tril(torch.ones((1, n_nodes, n_nodes)), diagonal=-1)\n",
    "#         self.d_mask = nn.Parameter(torch.tril(torch.ones((1, n_nodes, n_nodes)), diagonal=-1), requires_grad=True)\n",
    "#         self.d_mask = nn.Parameter(torch.ones((1, n_nodes, n_nodes)), requires_grad=True)\n",
    "#         self.d_mask = nn.Parameter(torch.ones((1, n_nodes, n_nodes)), requires_grad=True)\n",
    "        self.d_mask = testt.transpose(0,1)\n",
    "        self.encoder = Encoder(self.e_mask, n_nodes, d_embed, d_hidden, n_layers, n_heads, dropout)\n",
    "        self.decoder = Decoder(self.d_mask, n_nodes, d_embed, d_hidden, n_layers, n_heads, dropout)\n",
    "#         self.embedder = EmbedBlock(n_nodes, d_embed)\n",
    "        self.embedder = nn.Sequential(EmbedBlock(n_nodes, d_embed), PositionalEncoding(d_embed, dropout))\n",
    "        self.generator = EmbedBlock(d_embed, n_nodes)\n",
    "        self._init_weights()\n",
    "        \n",
    "    def _init_weights(self):\n",
    "        # This was important from their code. \n",
    "        # Initialize parameters with Glorot / fan_avg.\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "    \n",
    "    def encode(self, src):\n",
    "        src = self.embedder(src)\n",
    "        src = self.encoder(src)\n",
    "        return src\n",
    "    \n",
    "    def decode(self, tgt, memory):\n",
    "        tgt = self.embedder(tgt)\n",
    "        tgt = self.decoder(tgt, memory)\n",
    "        return tgt\n",
    "    \n",
    "    def forward(self, src, tgt):\n",
    "        \"Take in and process masked src and target sequences.\"\n",
    "        memory = self.encode(src)\n",
    "        tgt = self.decode(tgt, memory)\n",
    "        tgt = self.generator(tgt)\n",
    "        \n",
    "        return tgt, memory, F.softmax(-torch.exp(-(1e-10+torch.abs(self.d_mask)).log()), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalAttention(nn.Module):\n",
    "    def __init__(self, n_heads, d_embed, mask, mask_self=True, dropout=0.1):\n",
    "        \"Take in model size and number of n_headseads.\"\n",
    "        super(CausalAttention, self).__init__()\n",
    "        assert d_embed % n_heads == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_embed // n_heads\n",
    "        self.h = n_heads\n",
    "        self.linears = clones(nn.Linear(d_embed, d_embed), 4)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.eps = 1e-10\n",
    "        self.mask = mask\n",
    "        \n",
    "        if mask_self:\n",
    "            self.mask_add = torch.zeros((mask.shape[-1], mask.shape[-1])).unsqueeze(0)\n",
    "        else:\n",
    "            self.mask_add = torch.eye(mask.shape[-1]).unsqueeze(0)\n",
    "            \n",
    "    def add_mask(self):\n",
    "        return (self.eps+self.mask_add+torch.abs(self.mask)).unsqueeze(1)\n",
    "            \n",
    "    def get_mask(self):\n",
    "        return -torch.exp(-self.add_mask().log())\n",
    "    \n",
    "    def attention(self, query, key, value, dropout=None):\n",
    "        \"Compute 'Scaled Dot Product Attention'\"\n",
    "        d_k = query.size(-1)\n",
    "        scores = torch.matmul(query, key.transpose(-2,-1))/math.sqrt(d_k)\n",
    "#         scores += torch.abs(((self.mask_add+self.mask).unsqueeze(1)+self.eps)).log()\n",
    "#         scores += self.penalty()\n",
    "#         p_attn = F.softmax(scores, dim = -1)\n",
    "        p_attn = F.softmax(scores+self.get_mask(), dim = -1)\n",
    "    \n",
    "        if dropout is not None:\n",
    "            p_attn = dropout(p_attn)\n",
    "        return torch.matmul(p_attn, value), p_attn\n",
    "        \n",
    "    def forward(self, query, key, value):\n",
    "        \"Implements Figure 2\"\n",
    "        nbatches = query.size(0)\n",
    "        # batchwise linear projections from d_embed => n_heads x d_k \n",
    "        query, key, value = [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1,2)\n",
    "                             for l, x in zip(self.linears, (query, key, value))]\n",
    "        x, self.attn = self.attention(query, key, value, dropout=self.dropout)\n",
    "        \n",
    "        # view contatentation and apply final linear layer \n",
    "        x = x.transpose(1, 2).contiguous().view(nbatches, -1, self.h*self.d_k)\n",
    "        return self.linears[-1](x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VecBatch:\n",
    "    \"Object for holding a batch of data with mask during training.\"\n",
    "    def __init__(self, src, tgt=None, pad=0):\n",
    "        self.src = node_hot(src)\n",
    "        if tgt is not None:\n",
    "            self.tgt = node_hot(tgt[:, :], pad=(0,0))\n",
    "            self.tgt_y = node_hot(tgt[:, :], pad=(0,0))\n",
    "            self.ntokens = (self.tgt_y != pad).data.sum()\n",
    "            \n",
    "def data_graph_gen(spacetime, batch, nbatches):\n",
    "    for i in range(nbatches):\n",
    "        data = torch.squeeze(torch.from_numpy(g.data[i*batch:(i+1)*batch]))\n",
    "        src = Variable(data, requires_grad=False).float()\n",
    "        tgt = Variable(data, requires_grad=False).float()\n",
    "        yield VecBatch(src, tgt, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacetime.training_att import LagrangeLoss, ActionOpt\n",
    "from spacetime.training_att import h_A, h_A_timed\n",
    "from spacetime.utils_att import Parameters\n",
    "# from spacetime.training_att import train, truth_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, loss):\n",
    "    t = time.time()\n",
    "    model.train()    \n",
    "\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        preds, z_train, origin_A = model(batch.src.float(), batch.tgt.float())\n",
    "        if torch.sum(preds != preds):\n",
    "            raise ValueError('nan error\\n')\n",
    "        if torch.sum(origin_A != origin_A):\n",
    "            raise ValueError('nan error\\n')\n",
    "\n",
    "        loss(origin_A.squeeze(), preds, batch.src.float(), z_train)\n",
    "    loss.end_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the simple copy task.\n",
    "n_nodes=5\n",
    "d_embed = 10\n",
    "d_hidden=8*d_embed\n",
    "\n",
    "n_layers=2\n",
    "n_heads = 2\n",
    "dropout=0.1\n",
    "\n",
    "trn_params = Parameters(batch_size=100, epochs=5)\n",
    "opt_params = Parameters(constraint=lambda x: h_A(x, n_nodes),\n",
    "                        lr=0.005, l=1e-2, c=1e-3, h=np.inf, tau=1e-10, \n",
    "                        max_iters=50, h_tol=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0, Best Epoch: 4/5\n",
      "   ELBO: 12.1124894, KL: 10^0.984, NLL: 10^0.392 || h: 10^inf, c: 10^-3.000, l: 0.0100000, lr: 0.0014935\n",
      "Iteration: 1, Best Epoch: 4/5\n",
      "   ELBO: 1.2920252, KL: 10^-0.766, NLL: 10^0.050 || h: 10^-0.870, c: 10^-3.000, l: 0.0101349, lr: 0.0029920\n",
      "Iteration: 2, Best Epoch: 4/5\n",
      "   ELBO: 0.7292062, KL: 10^-1.066, NLL: 10^-0.192 || h: 10^-0.870, c: 10^-2.301, l: 0.0101349, lr: 0.0044905\n",
      "Iteration: 3, Best Epoch: 4/5\n",
      "   ELBO: 0.4583035, KL: 10^-1.337, NLL: 10^-0.385 || h: 10^-0.870, c: 10^-1.602, l: 0.0101349, lr: 0.0049900\n",
      "Iteration: 4, Best Epoch: 4/5\n",
      "   ELBO: 0.3475474, KL: 10^-1.523, NLL: 10^-0.498 || h: 10^-0.870, c: 10^-0.903, l: 0.0101349, lr: 0.0050000\n",
      "Iteration: 5, Best Epoch: 4/5\n",
      "   ELBO: 0.2953622, KL: 10^-1.613, NLL: 10^-0.567 || h: 10^-0.870, c: 10^-0.204, l: 0.0101349, lr: 0.0029430\n",
      "Iteration: 6, Best Epoch: 4/5\n",
      "   ELBO: 0.2770754, KL: 10^-1.665, NLL: 10^-0.593 || h: 10^-0.870, c: 10^0.495, l: 0.0101349, lr: 0.0020851\n",
      "Iteration: 7, Best Epoch: 2/5\n",
      "   ELBO: 0.2489413, KL: 10^-1.716, NLL: 10^-0.643 || h: 10^-0.870, c: 10^1.194, l: 0.0101349, lr: 0.0016145\n",
      "Iteration: 8, Best Epoch: 2/5\n",
      "   ELBO: 0.2324355, KL: 10^-1.735, NLL: 10^-0.670 || h: 10^-0.870, c: 10^1.893, l: 0.0101349, lr: 0.0013172\n",
      "Iteration: 9, Best Epoch: 4/5\n",
      "   ELBO: 0.2250562, KL: 10^-1.753, NLL: 10^-0.683 || h: 10^-0.870, c: 10^2.592, l: 0.0101349, lr: 0.0011124\n",
      "Iteration: 10, Best Epoch: 0/5\n",
      "   ELBO: 0.2172293, KL: 10^-1.791, NLL: 10^-0.700 || h: 10^-0.870, c: 10^3.291, l: 0.0101349, lr: 0.0009627\n",
      "\n",
      "Trial 0 finished in 59.37730813026428 seconds\n"
     ]
    }
   ],
   "source": [
    "n_trials = 1\n",
    "shd_trials, err_trials = list(), list()\n",
    "graph_trials = list()\n",
    "\n",
    "loss_log = {k:[] for k in ('elbo', 'kld', 'nll')}\n",
    "param_log = {k:[] for k in ('lr', 'l', 'c', 'h')}\n",
    "\n",
    "for trial in range(n_trials):\n",
    "    shd_train, err_train = list(), list()\n",
    "    graph_train = list()\n",
    "    #===================================\n",
    "    # load modules\n",
    "    #===================================\n",
    "\n",
    "    autoencoder = EncoderDecoder(n_nodes, d_embed, d_hidden, n_layers, n_heads, dropout)\n",
    "    optimizerL = ActionOpt(autoencoder, opt_params, h_factor=0.25*(2), c_factor=10.0/(2), warmups=1000)\n",
    "    lossL = LagrangeLoss(opt=optimizerL)\n",
    "    \n",
    "    #===================================\n",
    "    # train model\n",
    "    #===================================\n",
    "    \n",
    "    t_total = time.time()\n",
    "    while optimizerL._iter < optimizerL.max_iter:\n",
    "        for epoch in range(trn_params.epochs):\n",
    "            train(autoencoder, data_graph_gen(g, 30, 60), lossL)\n",
    "#             shd, err = truth_evaluation(g.adj, optimizerL, mod_params.graph_threshold)\n",
    "#             shd_train.append(shd)\n",
    "#             err_train.append(err)\n",
    "#             graph_train.append(optimizerL.adj.data.clone())\n",
    "        \n",
    "        print(\"Iteration: %s, Best Epoch: %s/%s\"%(optimizerL._iter, optimizerL.best_epoch, trn_params.epochs))\n",
    "        print(\"   ELBO: {:.7f}, KL: 10^{:.3f}, NLL: 10^{:.3f} || h: 10^{:.3f}, c: 10^{:.3f}, l: {:.7f}, lr: {:.7f}\".format(\n",
    "            optimizerL.min_elbo, np.log10(optimizerL.min_kld), np.log10(optimizerL.min_nll),\n",
    "            np.log10(optimizerL.h), np.log10(optimizerL.c), optimizerL.l, optimizerL.log['lr'][-1])\n",
    "        )\n",
    "\n",
    "        # update parameters\n",
    "        optimizerL.iterate()\n",
    "        if optimizerL.h <= optimizerL.h_tol or optimizerL._iter > 10:\n",
    "            break\n",
    "\n",
    "    print(\"\\nTrial %s finished in %s seconds\"%(trial, time.time() - t_total))\n",
    "#     print('Best ELBO Stats: shd %s err %s\\n'%(shd, err))\n",
    "\n",
    "#     shd_trials.append(shd_train)\n",
    "#     err_trials.append(err_train)\n",
    "#     graph_trials.append(optimizerL.show_adj(mod_params.graph_threshold))\n",
    "    \n",
    "    for k,v in loss_log.items():\n",
    "        v += [optimizerL.log[k]]\n",
    "        \n",
    "    for k,v in param_log.items():\n",
    "        v += [optimizerL.log[k]]\n",
    "pass;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe40d3670f0>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe40c2669e8>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize=(10, 3))\n",
    "axs[0].plot(range(len(optimizerL.log['c'])), np.log10(optimizerL.log['c']))\n",
    "axs[1].plot(range(len(optimizerL.log['lr'])), optimizerL.log['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold(adj, threshold):\n",
    "    return nn.Threshold(threshold, 0.0)(adj)-nn.Threshold(threshold, 0.0)(-adj)\n",
    "\n",
    "def time_scores(adj):\n",
    "    n_nodes = adj.shape[0]\n",
    "    I = torch.eye(n_nodes).double()\n",
    "    expA = torch.matrix_power(I+(1/n_nodes)*torch.tanh(adj)**2, n_nodes)\n",
    "    scores = torch.div(1.0, torch.sum(expA, dim=1))-torch.div(1.0, torch.sum(expA, dim=0))\n",
    "    return scores\n",
    "\n",
    "testdata = iter(data_graph_gen(g, 30, 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(testdata)\n",
    "preds, z_train, origin_A = autoencoder(batch.src.float(), batch.tgt.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4302,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.1835,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.5552,  0.0000,  0.1553],\n",
       "         [ 0.2012, -0.2138,  0.0000, -1.9856,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000, -3.0806]]],\n",
       "       grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4071,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.2980,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.5741,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000, -2.2069,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000, -3.2560]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold(preds[:1],0.1)\n",
    "threshold(batch.src.float()[:1], 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'blah' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-4cbd040533a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mblah\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'blah' is not defined"
     ]
    }
   ],
   "source": [
    "blah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_norm = F.softmax(-torch.exp(-(torch.abs(autoencoder.d_mask)+1e-10).log()), dim = -1)\n",
    "\n",
    "autoencoder.d_mask\n",
    "autoencoder.e_mask\n",
    "threshold(mask_norm, 0.1)\n",
    "\n",
    "optimizerL.constraint(mask_norm.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testt2 = torch.Tensor([[ 2.6456e-06, -9.5818e-08, -8.6945e-01,  2.0426e-02,  5.9849e-03],\n",
    "        [-1.0854e-07,  2.3277e-06,  2.6204e-02, -5.4377e-01, -1.4878e+00],\n",
    "        [-1.7013e-05,  2.5015e-09,  2.7552e-06, -1.5096e+00,  3.8229e-02],\n",
    "        [ 2.6729e-05, -1.0530e-05, -2.9288e-05,  2.4118e-06,  1.2162e+00],\n",
    "        [ 3.2156e-05, -4.2439e-05, -3.4324e-05,  2.3741e-05,  2.5642e-06]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-torch.exp(-(torch.abs(testt2+1e-10).log()))\n",
    "F.softmax(-torch.exp(-(torch.abs(testt2)+1e-10).log()), dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.exp(-torch.exp(-(torch.abs(testt2)+1e-10).log()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-torch.exp(-(torch.abs(testt2)+1e-10).log())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-1/(torch.abs(testt2)+1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.abs(testt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold(testt2, 0.1)\n",
    "threshold(-torch.exp(-(torch.abs(testt2)+1e-10).log()), 0.1)\n",
    "threshold(F.softmax(-torch.exp(-(torch.abs(testt2)+1e-10).log()), dim = -1), 0.1)\n",
    "threshold(torch.exp(-torch.exp(-(torch.abs(testt2)+1e-10).log())), 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -torch.exp(-(torch.eye(autoencoder.d_mask.shape[1])+1e-10).log())\n",
    "# -torch.exp(-5*(torch.abs(autoencoder.d_mask)+1e-4).log())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize=(10, 5))\n",
    "draw(torch.abs(autoencoder.d_mask.detach().squeeze()), list(range(5)), list(range(5)) if n_heads ==0 else [], ax=axs[0])\n",
    "draw(torch.abs(mask_norm.detach().squeeze()), list(range(5)), list(range(5)) if n_heads ==0 else [], ax=axs[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.draw_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_scores(mask_norm.squeeze().transpose(0,1))\n",
    "torch.argsort(time_scores(mask_norm.squeeze().transpose(0,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent = list(range(5))\n",
    "# tgt_sent = list(range(5))\n",
    "\n",
    "# autoencoder.decoder.layers[0].self_attn.attn[0, 1].data\n",
    "\n",
    "# for layer in range(0,2):\n",
    "#     fig, axs = plt.subplots(1,2, figsize=(10, 10))\n",
    "#     print(\"Decoder Self Layer\", layer+1)\n",
    "#     for h in range(2):\n",
    "#         draw(autoencoder.decoder.layers[layer].self_attn.attn[0, h].data[:len(tgt_sent), :len(tgt_sent)], \n",
    "#             tgt_sent[:-1], tgt_sent[:-1] if h ==0 else [], ax=axs[h])\n",
    "#     plt.show()\n",
    "#     print(\"Decoder Src Layer\", layer+1)\n",
    "#     fig, axs = plt.subplots(1,2, figsize=(10, 10))\n",
    "#     for h in range(2):\n",
    "#         draw(autoencoder.decoder.layers[layer].src_attn.attn[0, h].data[:len(tgt_sent)+1, :len(sent)+1], \n",
    "#             sent, tgt_sent if h ==0 else [], ax=axs[h])\n",
    "#     plt.show()\n",
    "# pass;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoamOpt:\n",
    "    \"Optim wrapper that implements rate.\"\n",
    "    def __init__(self, model_size, factor, warmup, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        self._step = 0\n",
    "        self.warmup = warmup\n",
    "        self.factor = factor\n",
    "        self.model_size = model_size\n",
    "        self._rate = 0\n",
    "        \n",
    "    def step(self):\n",
    "        \"Update parameters and rate\"\n",
    "        self._step += 1\n",
    "        rate = self.rate()\n",
    "        for p in self.optimizer.param_groups:\n",
    "            p['lr'] = rate\n",
    "        self._rate = rate\n",
    "        self.optimizer.step()\n",
    "        \n",
    "    def rate(self, step = None):\n",
    "        \"Implement `lrate` above\"\n",
    "        if step is None:\n",
    "            step = self._step\n",
    "        return self.factor * \\\n",
    "            (self.model_size ** (-0.5) *\n",
    "            min(step ** (-0.5), step * self.warmup ** (-1.5)))\n",
    "\n",
    "class KLSimple(nn.Module):\n",
    "    \"KL Loss\"\n",
    "    def __init__(self, generator, opt=None):\n",
    "        super(KLSimple, self).__init__()\n",
    "        self.generator = generator\n",
    "#         self.criterion = nn.KLDivLoss(reduction='sum')\n",
    "        self.criterion = LagrangeLoss.nll_gauss\n",
    "        self.opt = opt\n",
    "        \n",
    "    def __call__(self, mask, memory, x, y, norm):\n",
    "        loss = 0.1*torch.sum(torch.abs(mask)) + self.criterion(x, y, 0.0)/norm\n",
    "        loss.backward()\n",
    "        if self.opt is not None:\n",
    "            self.opt.step()\n",
    "            self.opt.optimizer.zero_grad()\n",
    "\n",
    "        return loss.data.item()*norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_graph_epoch(data_iter, model, loss_compute):\n",
    "    \"Standard Training and Logging Function\"\n",
    "    start = time.time()\n",
    "    total_tokens = 0\n",
    "    total_loss = 0\n",
    "    tokens = 0\n",
    "    for i, batch in enumerate(data_iter):\n",
    "        out, memory, mask = model.forward(batch.src.float(), batch.tgt.float())\n",
    "        loss = loss_compute(mask, memory, out, batch.tgt_y.float(), batch.ntokens)\n",
    "#         print(loss.item(), total_tokens)\n",
    "        total_loss += loss\n",
    "        total_tokens += batch.ntokens\n",
    "        tokens += batch.ntokens\n",
    "        if i % 50 == 1:\n",
    "            elapsed = time.time() - start\n",
    "            print(\"Epoch Step: %d Loss: %f Tokens per Sec: %f\" %\n",
    "                    (i, loss / batch.ntokens, tokens / elapsed))\n",
    "            start = time.time()\n",
    "            tokens = 0\n",
    "    return total_loss / total_tokens\n",
    "\n",
    "# Train the simple copy task.\n",
    "n_nodes=5\n",
    "d_embed = 10\n",
    "d_hidden=4*d_embed\n",
    "\n",
    "n_layers= 4\n",
    "n_heads = 2\n",
    "dropout=0.1\n",
    "\n",
    "model = EncoderDecoder(n_nodes, d_embed, d_hidden, n_layers, n_heads, dropout)\n",
    "model_opt = NoamOpt(d_embed, 1, 400, torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n",
    "lossKL = KLSimple(model.generator, model_opt)\n",
    "\n",
    "for epoch in range(5):\n",
    "    model.train()\n",
    "    run_graph_epoch(data_graph_gen(g, 30, 60), model, lossKL)\n",
    "    model.eval()\n",
    "    eval_results = run_graph_epoch(data_graph_gen(g, 30, 5), model, KLSimple(model.generator, None))\n",
    "    print(\"Results: %s\"%eval_results)\n",
    "pass;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = iter(data_graph_gen(g, 100, 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(testdata)\n",
    "preds, z_train, mask = model.forward(batch.src.float(), batch.tgt.float())\n",
    "preds[:1]\n",
    "batch.tgt_y[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = next(testdata)\n",
    "# preds, z_train, mask = model.forward(batch.src.float(), batch.tgt.float())\n",
    "# test_loss = nn.KLDivLoss(reduction='sum')\n",
    "\n",
    "# lossKL(mask, z_train, preds, batch.tgt_y.float(), batch.ntokens)\n",
    "# test_loss(preds[:1], batch.tgt_y[:1])+0.1*torch.sum(torch.abs(mask))\n",
    "# 0.1*torch.sum(torch.abs(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = list(range(batch.src.shape[1]))\n",
    "tgt_sent = list(range(preds.shape[1]))\n",
    "\n",
    "fig, axs = plt.subplots(1,1, figsize=(5, 5))\n",
    "draw(20*mask.detach().squeeze(), tgt_sent[:-1], tgt_sent[:-1] if n_heads ==0 else [], ax=axs)\n",
    "model.decoder.mask\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.decoder.layers[0].self_attn.attn[0, 1].data\n",
    "\n",
    "for layer in range(0,2):\n",
    "    fig, axs = plt.subplots(1,2, figsize=(10, 10))\n",
    "    print(\"Decoder Self Layer\", layer+1)\n",
    "    for h in range(2):\n",
    "        draw(model.decoder.layers[layer].self_attn.attn[0, h].data[:len(tgt_sent), :len(tgt_sent)], \n",
    "            tgt_sent[:-1], tgt_sent[:-1] if h ==0 else [], ax=axs[h])\n",
    "    plt.show()\n",
    "    print(\"Decoder Src Layer\", layer+1)\n",
    "    fig, axs = plt.subplots(1,2, figsize=(10, 10))\n",
    "    for h in range(2):\n",
    "        draw(model.decoder.layers[layer].src_attn.attn[0, h].data[:len(tgt_sent)+1, :len(sent)+1], \n",
    "            sent, tgt_sent if h ==0 else [], ax=axs[h])\n",
    "    plt.show()\n",
    "pass;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "blah"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEM Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "data = next(iter(test_loader))[0].double()\n",
    "_, noise, _, _, _, _, Wa_train = encoder(data)\n",
    "_, preds = decoder(noise, g_learned.torch_graph(), Wa_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wa_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = NodeData(g.data, bins=10)\n",
    "Z_learned = NodeData(noise.detach().numpy(), bins=10)\n",
    "X_learned = NodeData(preds.detach().numpy(), bins=10)\n",
    "\n",
    "pX_train = GraphSampler(g, X_train)\n",
    "pZ_learned = GraphSampler(g_learned, Z_learned)\n",
    "pX_learned = GraphSampler(g_learned, X_learned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_resampled_cdf = NodeData(pZ_learned.resample_from_cdf(size=10000), bins = Z_learned.edges())\n",
    "Z_resampled_pdf = NodeData(pZ_learned.resample_from_pdf(size=10000), bins = Z_learned.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pZ_resampled_cdf = GraphSampler(g_learned, Z_resampled_cdf)\n",
    "pZ_resampled_pdf = GraphSampler(g_learned, Z_resampled_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, preds_resampled_cdf = decoder(g_learned.torch_data(Z_resampled_cdf.data()), g_learned.torch_graph(), Wa_train)\n",
    "_, preds_resampled_pdf = decoder(g_learned.torch_data(Z_resampled_pdf.data()), g_learned.torch_graph(), Wa_train)\n",
    "X_resampled_cdf = NodeData(preds_resampled_cdf.detach().numpy(), bins=15)\n",
    "X_resampled_pdf = NodeData(preds_resampled_pdf.detach().numpy(), bins=15)\n",
    "\n",
    "pX_resampled_cdf = GraphSampler(g_learned, X_resampled_cdf)\n",
    "pX_resampled_pdf = GraphSampler(g_learned, X_resampled_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 4, sharex='col', sharey='col', figsize = (16,9))\n",
    "for col, (d,c) in col_plot_dict.items():\n",
    "    axs[0][col].set_title(r'$P_Z(%s|%s)$    (true histo)'%(d,c))\n",
    "    axs[0][col].contour(*pZ_learned.get_contour_conditional(d,c), levels=50)\n",
    "    axs[1][col].set_title(r'$P_Z(%s|%s)$    (cdf resampled histo)'%(d,c))\n",
    "    axs[1][col].contour(*pZ_resampled_cdf.get_contour_conditional(d,c), levels=50)\n",
    "    axs[2][col].set_title(r'$P_Z(%s|%s)$    (pdf resampled histo)'%(d,c))\n",
    "    axs[2][col].contour(*pZ_resampled_pdf.get_contour_conditional(d,c), levels=50)\n",
    "pass;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 4, sharex='col', sharey='col', figsize = (16,9))\n",
    "for col, (d,c) in col_plot_dict.items():\n",
    "    axs[0][col].set_title(r'$P_X(%s|%s)$    (true histo)'%(d,c))\n",
    "    axs[0][col].contour(*pX_train.get_contour_conditional(d,c), levels=50)\n",
    "    axs[1][col].set_title(r'$P_X(%s|%s)$    (cdf resampled histo)'%(d,c))\n",
    "    axs[1][col].contour(*pX_resampled_cdf.get_contour_conditional(d,c), levels=50)\n",
    "    axs[2][col].set_title(r'$P_X(%s|%s)$    (pdf resampled histo)'%(d,c))\n",
    "    axs[2][col].contour(*pX_resampled_pdf.get_contour_conditional(d,c), levels=50)\n",
    "pass;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(pX_train.node_data.axes(0)[0], pX_train.histogram.compute_joint(0)[1])\n",
    "# plt.plot(pX_train.node_data.axes(1)[0], pX_train.histogram.compute_joint(1)[1])\n",
    "# plt.show()\n",
    "# plt.plot(pX_mutil.node_data.axes(0)[0], pX_mutil.histogram.compute_joint(0)[1])\n",
    "# plt.plot(pX_mutil.node_data.axes(1)[0], pX_mutil.histogram.compute_joint(1)[1])\n",
    "# pass;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# truth = pX.histogram.compute_conditional(4,(2,))[1]\n",
    "# generated = pX_new.histogram.compute_conditional(4,(2,))[1]\n",
    "# _, truth_ = pX.histogram._epsilonize((), truth)\n",
    "# _, generated_ = pX.histogram._epsilonize((), generated)\n",
    "# np.sum(truth_*np.log((truth_/generated_)))/np.prod(truth.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.sum(truth)\n",
    "# np.sum(truth_*np.log((truth_/generated_)), axis=0, keepdims=True)\n",
    "# np.exp(np.sum(-truth_*np.log((truth_/(truth_*0.1)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Mutilation Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_mutil = spacetime_mutilator(g, mutilate=[mutilate])\n",
    "g_mutil.data = Simulator.sem(graph=g_mutil.graph, n=10000, x_dims=args.x_dims, \n",
    "                             sem_type=args.graph_sem_type, linear_type=args.graph_linear_type, \n",
    "                             noise_scale=args.noise_scale, seed=args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_learned.draw_graph()\n",
    "\n",
    "g_learned_mutil = spacetime_mutilator(g_learned, mutilate=[mutilate])\n",
    "g_learned_mutil.draw_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mutil = NodeData(g_mutil.data, bins=10)\n",
    "pX_mutil = GraphSampler(g, X_mutil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_resampled_mutil_cdf = NodeData(pZ_learned.resample_from_cdf(size=10000, mutilate=[mutilate]), bins = Z_learned.edges())\n",
    "Z_resampled_mutil_pdf = NodeData(pZ_learned.resample_from_pdf(size=10000, mutilate=[mutilate]), bins = Z_learned.edges())\n",
    "pZ_resampled_mutil_cdf = GraphSampler(g_learned, Z_resampled_mutil_cdf)\n",
    "pZ_resampled_mutil_pdf = GraphSampler(g_learned, Z_resampled_mutil_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, preds_resampled_mutil_cdf = decoder(g_learned_mutil.torch_data(Z_resampled_mutil_cdf.data()), \n",
    "                                       g_learned_mutil.torch_graph(), Wa_train)\n",
    "_, preds_resampled_mutil_pdf = decoder(g_learned_mutil.torch_data(Z_resampled_mutil_pdf.data()), \n",
    "                                       g_learned_mutil.torch_graph(), Wa_train)\n",
    "X_resampled_mutil_cdf = NodeData(preds_resampled_mutil_cdf.detach().numpy(), bins=X_learned.edges())\n",
    "X_resampled_mutil_pdf = NodeData(preds_resampled_mutil_pdf.detach().numpy(), bins=X_learned.edges())\n",
    "pX_resampled_mutil_cdf = GraphSampler(g_learned_mutil, X_resampled_mutil_cdf)\n",
    "pX_resampled_mutil_pdf = GraphSampler(g_learned_mutil, X_resampled_mutil_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 4, sharex='col', sharey='col', figsize = (16,12))\n",
    "for col, (d,c) in col_plot_dict.items():\n",
    "    axs[0][col].set_title(r'$P_X(%s|%s)$    (true histo)'%(d,c))\n",
    "    axs[0][col].contour(*pX_train.get_contour_conditional(d,c), levels=50)\n",
    "    axs[1][col].set_title(r'$P_X(%s|%s)$    (true mutil histo)'%(d,c))\n",
    "    axs[1][col].contour(*pX_mutil.get_contour_conditional(d,c), levels=50)\n",
    "    axs[2][col].set_title(r'$P_X(%s|%s)$    (cdf resampled mutil histo)'%(d,c))\n",
    "    axs[2][col].contour(*pX_resampled_mutil_cdf.get_contour_conditional(d,c), levels=50)\n",
    "    axs[3][col].set_title(r'$P_X(%s|%s)$    (pdf resampled mutil histo)'%(d,c))\n",
    "    axs[3][col].contour(*pX_resampled_mutil_pdf.get_contour_conditional(d,c), levels=50)\n",
    "    \n",
    "pass;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 3, sharex='col', sharey='col', figsize = (12,9))\n",
    "\n",
    "axs[0][0].set_title(r'$P_Z(%s|%s)$    (pdf resampled histo)'%(observe,mutilate))\n",
    "axs[0][0].contour(*pZ_resampled_pdf.get_contour_conditional(observe,mutilate), levels=50)\n",
    "axs[1][0].set_title(r'$P_Z(%s|%s)$    (cdf resampled mutil histo)'%(observe,mutilate))\n",
    "axs[1][0].contour(*pZ_resampled_mutil_cdf.get_contour_conditional(observe,mutilate), levels=50)\n",
    "axs[2][0].set_title(r'$P_Z(%s|%s)$    (pdf resampled mutil histo)'%(observe,mutilate))\n",
    "axs[2][0].contour(*pZ_resampled_mutil_pdf.get_contour_conditional(observe,mutilate), levels=50)\n",
    "pass;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pi_UNj_DOk(i, j, k, histogram):\n",
    "    do = np.zeros(histogram.compute_joint(i, k)[1].shape)\n",
    "    latent = histogram.compute_joint(j)[1]\n",
    "    \n",
    "    for n in range(len(latent)):\n",
    "        do += histogram.compute_conditional(i,(j,k))[1][:,n,:]*latent[n]\n",
    "    return do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 3, sharex=True, sharey=True, figsize = (12,9))\n",
    "axs[0][0].set_title(r'$P_X(%s|%s)$    (true histo)'%(observe,mutilate))\n",
    "axs[0][0].contour(*pX_train.get_contour_conditional(observe,mutilate), levels=50)\n",
    "axs[1][0].set_title(r'$P_X(%s|%s)$    (cdf resampled histo)'%(observe,mutilate))\n",
    "axs[1][0].contour(*pX_resampled_cdf.get_contour_conditional(observe,mutilate), levels=50)\n",
    "axs[2][0].set_title(r'$P_X(%s|%s)$    (pdf resampled histo)'%(observe,mutilate))\n",
    "axs[2][0].contour(*pX_resampled_pdf.get_contour_conditional(observe,mutilate), levels=50)\n",
    "\n",
    "axs[0][1].set_title(r'$P_X(%s|%s)$    (true mutil histo)'%(observe,mutilate))\n",
    "axs[0][1].contour(*pX_mutil.get_contour_conditional(observe,mutilate), levels=50)\n",
    "axs[1][1].set_title(r'$P_X(%s|%s)$    (cdf resampled mutil histo)'%(observe,mutilate))\n",
    "axs[1][1].contour(*pX_resampled_mutil_cdf.get_contour_conditional(observe,mutilate), levels=50)\n",
    "axs[2][1].set_title(r'$P_X(%s|%s)$    (pdf resampled mutil histo)'%(observe,mutilate))\n",
    "axs[2][1].contour(*pX_resampled_mutil_pdf.get_contour_conditional(observe,mutilate), levels=50)\n",
    "\n",
    "\n",
    "\n",
    "axs[0][2].set_title(r'$P_X(%s|%s)$    (true adjusted histo)'%(observe,mutilate))\n",
    "axs[0][2].contour(*np.meshgrid(*pX_train.node_data.axes(observe,mutilate)), \n",
    "                  Pi_UNj_DOk(observe,latent,mutilate, pX_train.histogram).T, levels=50)\n",
    "pass;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
